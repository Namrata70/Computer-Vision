{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\ncblrl467\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\ncblrl467\\anaconda3\\lib\\site-packages (from flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\ncblrl467\\anaconda3\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\ncblrl467\\anaconda3\\lib\\site-packages (from flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\ncblrl467\\anaconda3\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\ncblrl467\\anaconda3\\lib\\site-packages (from click>=8.0->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ncblrl467\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->flask) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python\n",
    "!pip3 install timm\n",
    "!pip3 install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\NCBLRL467/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NCBLRL467\\anaconda3\\Lib\\site-packages\\torch\\hub.py:295: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/rwightman/gen-efficientnet-pytorch/zipball/master\" to C:\\Users\\NCBLRL467/.cache\\torch\\hub\\master.zip\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_lite3-b733e338.pth\" to C:\\Users\\NCBLRL467/.cache\\torch\\hub\\checkpoints\\tf_efficientnet_lite3-b733e338.pth\n",
      "Downloading: \"https://github.com/isl-org/MiDaS/releases/download/v2_1/midas_v21_small_256.pt\" to C:\\Users\\NCBLRL467/.cache\\torch\\hub\\checkpoints\\midas_v21_small_256.pt\n",
      "100%|██████████| 81.8M/81.8M [00:48<00:00, 1.75MB/s]\n",
      "Using cache found in C:\\Users\\NCBLRL467/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.107:5000\n",
      "Press CTRL+C to quit\n",
      "192.168.1.107 - - [10/Aug/2024 15:43:13] \"GET / HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO WORLD TO The WORLD OF REAL-TIME DEPTH MAPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.107 - - [10/Aug/2024 15:43:29] \"GET /video_feed HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from flask import Flask, Response\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load a MiDas model for depth estimation\n",
    "model_type = \"MiDaS_small\"  # MiDaS v3 - Large (highest accuracy, slowest inference speed)\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "midas.eval()\n",
    "\n",
    "# Load transforms to resize and normalize the image\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "\n",
    "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "    transform = midas_transforms.dpt_transform\n",
    "else:\n",
    "    transform = midas_transforms.small_transform\n",
    "\n",
    "# Open up the video capture from a webcam\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "def generate_frames():\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Apply input transforms\n",
    "        input_batch = transform(img).to(device)\n",
    "\n",
    "        # Prediction and resize to original resolution\n",
    "        with torch.no_grad():\n",
    "            prediction = midas(input_batch)\n",
    "\n",
    "            prediction = torch.nn.functional.interpolate(\n",
    "                prediction.unsqueeze(1),\n",
    "                size=img.shape[:2],\n",
    "                mode=\"bicubic\",\n",
    "                align_corners=False,\n",
    "            ).squeeze()\n",
    "\n",
    "        depth_map = prediction.cpu().numpy()\n",
    "        depth_map = cv2.normalize(depth_map, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_64F)\n",
    "\n",
    "        end = time.time()\n",
    "        totalTime = end - start\n",
    "\n",
    "        fps = 1 / totalTime\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        depth_map = (depth_map * 255).astype(np.uint8)\n",
    "        depth_map = cv2.applyColorMap(depth_map, cv2.COLORMAP_MAGMA)\n",
    "\n",
    "        cv2.putText(img, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Combine the original image and depth map side by side\n",
    "        combined_image = cv2.hconcat([img, depth_map])\n",
    "\n",
    "        # Encode the combined image as JPEG\n",
    "        _, buffer = cv2.imencode('.jpg', combined_image)\n",
    "        frame = buffer.tobytes()\n",
    "\n",
    "        # Generate the response for the frame\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    # Video streaming route\n",
    "    print('HELLO TO THE WORLD OF REAL-TIME DEPTH MAPS')\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
